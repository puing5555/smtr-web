"""
íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ ê°œì„  ìŠ¤í¬ë¦½íŠ¸
- ê¸°ì¡´ ìë§‰ì—ì„œ ì‹œê·¸ë„ ì¸ìš©ë¬¸ì— í•´ë‹¹í•˜ëŠ” ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ì°¾ê¸°
- ë” ë‚˜ì€ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
"""
import json
import os
import re
import sys
import io
from difflib import SequenceMatcher

# UTF-8 ì¶œë ¥ ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', line_buffering=True)
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', line_buffering=True)

def load_subtitle_with_timestamps(video_id):
    """ìë§‰ íŒŒì¼ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í…ìŠ¤íŠ¸ ìŒ ì¶”ì¶œ"""
    subtitle_paths = [
        f'C:\\Users\\Mario\\work\\invest-sns\\smtr_data\\corinpapa1106\\{video_id}.txt',
        f'C:\\Users\\Mario\\.openclaw\\workspace\\smtr_data\\corinpapa1106\\{video_id}.txt'
    ]
    
    for subtitle_path in subtitle_paths:
        if os.path.exists(subtitle_path):
            try:
                with open(subtitle_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # SRT/VTT í˜•ì‹ íŒŒì‹±
                timestamp_entries = []
                
                # SRT í˜•ì‹ (ì˜ˆ: 00:02:45,123 --> 00:02:47,456)
                srt_pattern = r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*\n(.*?)(?=\n\d+\s*\n|\n\n|\Z)'
                srt_matches = re.findall(srt_pattern, content, re.DOTALL)
                
                for start_time, end_time, text in srt_matches:
                    start_seconds = parse_timestamp(start_time)
                    text_clean = re.sub(r'\n', ' ', text).strip()
                    if start_seconds and text_clean:
                        timestamp_entries.append((start_seconds, text_clean))
                
                # VTT í˜•ì‹ë„ ì‹œë„ (ì˜ˆ: 00:02:45.123 --> 00:02:47.456)
                if not timestamp_entries:
                    vtt_pattern = r'(\d{2}:\d{2}:\d{2}\.\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}\.\d{3})\s*\n(.*?)(?=\n\d{2}:\d{2}:\d{2}|\n\n|\Z)'
                    vtt_matches = re.findall(vtt_pattern, content, re.DOTALL)
                    
                    for start_time, end_time, text in vtt_matches:
                        start_seconds = parse_timestamp(start_time)
                        text_clean = re.sub(r'\n', ' ', text).strip()
                        if start_seconds and text_clean:
                            timestamp_entries.append((start_seconds, text_clean))
                
                # ê°„ë‹¨í•œ íƒ€ì„ìŠ¤íƒ¬í”„ + í…ìŠ¤íŠ¸ í˜•ì‹ (ì˜ˆ: 02:45 í…ìŠ¤íŠ¸ë‚´ìš©)
                if not timestamp_entries:
                    simple_pattern = r'(\d{1,2}:\d{2}(?::\d{2})?)\s+(.+)'
                    lines = content.split('\n')
                    for line in lines:
                        match = re.match(simple_pattern, line.strip())
                        if match:
                            time_str, text = match.groups()
                            seconds = parse_simple_timestamp(time_str)
                            if seconds:
                                timestamp_entries.append((seconds, text.strip()))
                
                print(f"ğŸ“„ ìë§‰ íŒŒì‹±: {subtitle_path} - {len(timestamp_entries)}ê°œ ì—”íŠ¸ë¦¬")
                return timestamp_entries
                
            except Exception as e:
                print(f"âš ï¸ ìë§‰ íŒŒì‹± ì‹¤íŒ¨: {subtitle_path} - {e}")
                continue
    
    print(f"âŒ ìë§‰ íŒŒì¼ ì—†ìŒ: {video_id}")
    return []

def parse_timestamp(timestamp_str):
    """íƒ€ì„ìŠ¤íƒ¬í”„ ë¬¸ìì—´ì„ ì´ˆë¡œ ë³€í™˜ (SRT/VTT í˜•ì‹)"""
    try:
        # ì‰¼í‘œë¥¼ ì ìœ¼ë¡œ ë³€í™˜ (SRTì˜ ê²½ìš°)
        timestamp_str = timestamp_str.replace(',', '.')
        
        # HH:MM:SS.mmm í˜•ì‹ íŒŒì‹±
        parts = timestamp_str.split(':')
        if len(parts) == 3:
            hours = int(parts[0])
            minutes = int(parts[1])
            seconds_parts = parts[2].split('.')
            seconds = int(seconds_parts[0])
            milliseconds = int(seconds_parts[1]) if len(seconds_parts) > 1 else 0
            
            total_seconds = hours * 3600 + minutes * 60 + seconds + milliseconds / 1000
            return total_seconds
    except:
        pass
    return None

def parse_simple_timestamp(timestamp_str):
    """ê°„ë‹¨í•œ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì´ˆë¡œ ë³€í™˜ (MM:SS ë˜ëŠ” HH:MM:SS)"""
    try:
        parts = timestamp_str.split(':')
        if len(parts) == 2:  # MM:SS
            minutes = int(parts[0])
            seconds = int(parts[1])
            return minutes * 60 + seconds
        elif len(parts) == 3:  # HH:MM:SS
            hours = int(parts[0])
            minutes = int(parts[1])
            seconds = int(parts[2])
            return hours * 3600 + minutes * 60 + seconds
    except:
        pass
    return None

def similarity(text1, text2):
    """ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0-1)"""
    # í…ìŠ¤íŠ¸ ì •ê·œí™”
    text1 = normalize_text(text1)
    text2 = normalize_text(text2)
    
    if not text1 or not text2:
        return 0
    
    return SequenceMatcher(None, text1, text2).ratio()

def normalize_text(text):
    """í…ìŠ¤íŠ¸ ì •ê·œí™” (ê³µë°±, êµ¬ë‘ì  ë“± ì œê±°)"""
    if not text:
        return ""
    
    # ë”°ì˜´í‘œ, êµ¬ë‘ì  ì œê±°
    text = re.sub(r'["""\'\'.,!?;:]', '', text)
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text)
    return text.lower().strip()

def find_best_timestamp(quote_text, timestamp_entries, min_similarity=0.3):
    """ì¸ìš©ë¬¸ì— ê°€ì¥ ì˜ ë§¤ì¹­ë˜ëŠ” íƒ€ì„ìŠ¤íƒ¬í”„ ì°¾ê¸°"""
    best_timestamp = None
    best_similarity = 0
    best_match_text = ""
    
    quote_normalized = normalize_text(quote_text)
    if not quote_normalized or len(quote_normalized) < 5:
        return None, 0, ""
    
    for timestamp, text in timestamp_entries:
        sim = similarity(quote_text, text)
        
        if sim > best_similarity and sim >= min_similarity:
            best_similarity = sim
            best_timestamp = timestamp
            best_match_text = text
    
    # ë¶€ë¶„ ë§¤ì¹­ë„ ì‹œë„ (ê¸´ ì¸ìš©ë¬¸ì˜ ê²½ìš°)
    if not best_timestamp and len(quote_normalized) > 20:
        # ì¸ìš©ë¬¸ì˜ ì²˜ìŒ 10ë‹¨ì–´ë¡œ ë§¤ì¹­
        quote_words = quote_normalized.split()[:10]
        quote_short = ' '.join(quote_words)
        
        for timestamp, text in timestamp_entries:
            text_normalized = normalize_text(text)
            if quote_short in text_normalized or text_normalized in quote_short:
                sim = len(quote_short) / max(len(quote_short), len(text_normalized))
                if sim > best_similarity:
                    best_similarity = sim
                    best_timestamp = timestamp
                    best_match_text = text
    
    return best_timestamp, best_similarity, best_match_text

def improve_all_timestamps():
    """ëª¨ë“  ì‹œê·¸ë„ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ê°œì„ """
    # ì›ë³¸ ì‹œê·¸ë„ ë¡œë“œ
    signal_file = 'C:\\Users\\Mario\\work\\invest-sns\\smtr_data\\corinpapa1106\\_all_signals_194.json'
    with open(signal_file, 'r', encoding='utf-8') as f:
        signals = json.load(f)
    
    print(f"ğŸ”„ íƒ€ì„ìŠ¤íƒ¬í”„ ê°œì„  ì‹œì‘: {len(signals)}ê°œ ì‹œê·¸ë„")
    
    improved_signals = []
    stats = {
        'total': len(signals),
        'improved': 0,
        'already_had': 0,
        'failed': 0
    }
    
    # ë¹„ë””ì˜¤ë³„ë¡œ ìë§‰ ìºì‹±
    subtitle_cache = {}
    
    for i, signal in enumerate(signals):
        video_id = signal.get('video_id', '')
        content = signal.get('content', '')
        
        print(f"ğŸ“ ì²˜ë¦¬ ì¤‘ ({i+1}/{len(signals)}): {video_id} - {signal.get('asset', 'N/A')}")
        
        # ìë§‰ ë¡œë“œ (ìºì‹œ ì‚¬ìš©)
        if video_id not in subtitle_cache:
            subtitle_cache[video_id] = load_subtitle_with_timestamps(video_id)
        
        timestamp_entries = subtitle_cache[video_id]
        
        if not timestamp_entries:
            print(f"   âŒ ìë§‰ ì—†ìŒ")
            signal['timestamp_seconds'] = None
            signal['timestamp_confidence'] = 0
            signal['timestamp_match'] = ""
            stats['failed'] += 1
        else:
            # íƒ€ì„ìŠ¤íƒ¬í”„ ë§¤ì¹­
            timestamp, confidence, match_text = find_best_timestamp(content, timestamp_entries)
            
            if timestamp:
                signal['timestamp_seconds'] = timestamp
                signal['timestamp_confidence'] = confidence
                signal['timestamp_match'] = match_text
                
                minutes = int(timestamp // 60)
                seconds = int(timestamp % 60)
                print(f"   âœ… íƒ€ì„ìŠ¤íƒ¬í”„: {minutes:02d}:{seconds:02d} (ì‹ ë¢°ë„: {confidence:.2f})")
                stats['improved'] += 1
            else:
                signal['timestamp_seconds'] = None
                signal['timestamp_confidence'] = 0
                signal['timestamp_match'] = ""
                print(f"   âŒ ë§¤ì¹­ ì‹¤íŒ¨")
                stats['failed'] += 1
        
        improved_signals.append(signal)
    
    # ê°œì„ ëœ ê²°ê³¼ ì €ì¥
    output_file = 'C:\\Users\\Mario\\work\\invest-sns\\smtr_data\\corinpapa1106\\_signals_with_improved_timestamps.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(improved_signals, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ê°œì„ ëœ ê²°ê³¼ ì €ì¥: {output_file}")
    
    # í†µê³„ ì¶œë ¥
    print(f"\nğŸ“Š íƒ€ì„ìŠ¤íƒ¬í”„ ê°œì„  ê²°ê³¼:")
    print(f"   - ì „ì²´: {stats['total']}ê°œ")
    print(f"   - ê°œì„ ë¨: {stats['improved']}ê°œ ({stats['improved']/stats['total']*100:.1f}%)")
    print(f"   - ì‹¤íŒ¨: {stats['failed']}ê°œ ({stats['failed']/stats['total']*100:.1f}%)")
    
    return improved_signals, stats

if __name__ == "__main__":
    improve_all_timestamps()